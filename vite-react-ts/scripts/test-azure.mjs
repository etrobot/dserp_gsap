import { promises as fs } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// åŠ è½½ .env æ–‡ä»¶
async function loadEnv() {
  const envPath = path.join(__dirname, '../.env');
  const envContent = await fs.readFile(envPath, 'utf-8');
  envContent.split('\n').forEach(line => {
    const trimmed = line.trim();
    if (trimmed && !trimmed.startsWith('#')) {
      const [key, value] = trimmed.split('=');
      if (key && value) {
        process.env[key.trim()] = value.trim();
      }
    }
  });
}

async function testAzure() {
  await loadEnv();
  
  const speechKey = process.env.VITE_AZURE_SPEECH_KEY;
  const speechRegion = process.env.VITE_AZURE_SPEECH_REGION;
  
  console.log('ğŸ” æµ‹è¯• Azure è¿æ¥...');
  console.log(`   Key: ${speechKey.substring(0, 8)}...`);
  console.log(`   Region: ${speechRegion}`);
  
  try {
    const sdk = await import('microsoft-cognitiveservices-speech-sdk');
    const speechConfig = sdk.default.SpeechConfig.fromSubscription(
      speechKey,
      speechRegion
    );
    
    speechConfig.speechSynthesisVoiceName = 'zh-TW-YunJheNeural';
    
    console.log('âœ… Azure Speech Config å·²åˆå§‹åŒ–');
    console.log('âœ… å£°éŸ³å·²è®¾ç½®ä¸º: zh-TW-YunJheNeural');
    
    // åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºæµ‹è¯•
    const tempFile = `/tmp/test-tts-${Date.now()}.wav`;
    const audioConfig = sdk.default.AudioConfig.fromAudioFileOutput(tempFile);
    const synthesizer = new sdk.default.SpeechSynthesizer(speechConfig, audioConfig);
    
    console.log('ğŸ¤ å¼€å§‹åˆæˆè¯­éŸ³æµ‹è¯•...');
    
    return new Promise((resolve, reject) => {
      const testText = 'è¿™æ˜¯ä¸€æ¡æµ‹è¯•æ–‡æœ¬';
      
      synthesizer.speakTextAsync(
        testText,
        (result) => {
          if (result.reason === sdk.default.ResultReason.SynthesizingAudioCompleted) {
            console.log('âœ… è¯­éŸ³åˆæˆæˆåŠŸï¼');
            
            setTimeout(async () => {
              try {
                const stats = await fs.stat(tempFile);
                console.log(`âœ… éŸ³é¢‘æ–‡ä»¶ç”ŸæˆæˆåŠŸ`);
                console.log(`   æ–‡ä»¶å¤§å°: ${stats.size} bytes`);
                
                // æ¸…ç†
                await fs.unlink(tempFile);
                resolve();
              } catch (err) {
                console.error('âŒ æ–‡ä»¶æ£€æŸ¥å¤±è´¥:', err.message);
                reject(err);
              }
            }, 100);
          } else if (result.reason === sdk.default.ResultReason.Canceled) {
            const cancellation = sdk.default.SpeechSynthesisCancellationDetails.fromResult(result);
            console.error('âŒ è¯­éŸ³åˆæˆè¢«å–æ¶ˆ:', cancellation.errorDetails);
            reject(new Error(cancellation.errorDetails));
          }
        },
        (err) => {
          console.error('âŒ é”™è¯¯:', err);
          reject(err);
        }
      );
    });
  } catch (err) {
    console.error('âŒ æµ‹è¯•å¤±è´¥:', err.message);
    process.exit(1);
  }
}

testAzure().then(() => {
  console.log('\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹ç”Ÿæˆ TTS');
  console.log('   è¿è¡Œ: npm run tts ysjfTagInsightScript');
}).catch(err => {
  console.error('\nâŒ æµ‹è¯•å¤±è´¥');
  process.exit(1);
});
