#!/usr/bin/env node
/**
 * TTS æ‰¹é‡ç”Ÿæˆè„šæœ¬
 * ä½¿ç”¨ Azure TTS ä¸º read_srt ç”Ÿæˆè¯­éŸ³æ–‡ä»¶
 * 
 * ç¯å¢ƒå˜é‡ï¼ˆæ¥è‡ª .envï¼‰:
 *   VITE_AZURE_SPEECH_KEY: Azure Speech Service key
 *   VITE_AZURE_SPEECH_REGION: Azure Speech Service region
 * 
 * è¿è¡Œ:
 *   npm run tts [scriptName]
 * 
 * ç¤ºä¾‹:
 *   npm run tts ysjfTagInsightScript
 */

import { promises as fs } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { synthesizeSpeech } from '../src/utils/tts.js';

// æ‰‹åŠ¨åŠ è½½ .env æ–‡ä»¶
async function loadEnv() {
  const __filename = fileURLToPath(import.meta.url);
  const __dirname = path.dirname(__filename);
  const envPath = path.join(__dirname, '../.env');
  
  try {
    const envContent = await fs.readFile(envPath, 'utf-8');
    envContent.split('\n').forEach(line => {
      const trimmed = line.trim();
      if (trimmed && !trimmed.startsWith('#')) {
        const [key, value] = trimmed.split('=');
        if (key && value) {
          process.env[key.trim()] = value.trim();
        }
      }
    });
  } catch (err) {
    console.warn('âš ï¸  æ— æ³•è¯»å– .env æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç°æœ‰ç¯å¢ƒå˜é‡');
  }
}

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// é…ç½®
const CONFIG = {
  outputDir: path.join(__dirname, '../public/tts'),
  voice: 'zh-TW-YunJheNeural', // ç¹é«”ä¸­æ–‡è²éŸ³
};

// è§£æå‘½ä»¤è¡Œå‚æ•°
const scriptName = process.argv[2] || 'ysjfTagInsightScript';

// ä» JSON æ–‡ä»¶è¯»å–è„šæœ¬é…ç½®
async function loadScriptConfig(scriptName) {
  try {
    const scriptPath = path.join(__dirname, `../public/scripts/${scriptName}.json`);
    const content = await fs.readFile(scriptPath, 'utf-8');
    return JSON.parse(content);
  } catch (error) {
    console.error(`âŒ æ— æ³•è¯»å–è„šæœ¬æ–‡ä»¶: ${scriptName}.json`);
    throw error;
  }
}

// è·å–æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰
function getAudioDuration(buffer) {
  // WAV æ–‡ä»¶æ ¼å¼: ç¬¬ 24-27 å­—èŠ‚æ˜¯é‡‡æ ·ç‡ï¼Œç¬¬ 28-29 å­—èŠ‚æ˜¯å­—èŠ‚é€Ÿç‡
  // ç®€åŒ–ä¼°ç®—: PCM audio æ—¶é•¿ = æ–‡ä»¶å¤§å° / (é‡‡æ ·ç‡ * å­—èŠ‚æ¯ç§’)
  // å¯¹äº 16-bit stereo: æ—¶é•¿ = (æ–‡ä»¶å¤§å° - 44) / (é‡‡æ ·ç‡ * 4)
  // å‡è®¾ 16000 Hz é‡‡æ ·ç‡ï¼Œåˆ™: æ—¶é•¿ = (æ–‡ä»¶å¤§å° - 44) / 64000
  
  // æ›´å‡†ç¡®çš„æ–¹å¼ï¼šè¯»å– WAV æ–‡ä»¶å¤´
  if (buffer.length < 44) return 0;
  
  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.length);
  const sampleRate = view.getUint32(24, true); // å­—èŠ‚ 24-27
  const byteRate = view.getUint32(28, true);   // å­—èŠ‚ 28-31
  const blockAlign = view.getUint16(32, true); // å­—èŠ‚ 32-33
  const bitsPerSample = view.getUint16(34, true); // å­—èŠ‚ 34-35
  
  const audioDataSize = buffer.length - 44;
  const duration = audioDataSize / byteRate;
  
  return Math.round(duration * 100) / 100; // ä¿ç•™ä¸¤ä½å°æ•°
}

// æå–æ‰€æœ‰éœ€è¦åˆæˆçš„æ–‡æœ¬
function extractReadSrtItems(sections) {
  const items = [];
  const seen = new Set();
  
  for (const section of sections) {
    if (!section.content) continue;
    
    for (const item of section.content) {
      const text = item.read_srt?.trim();
      if (text && !seen.has(text)) {
        seen.add(text);
        items.push({
          text,
          sectionId: section.id,
          itemIndex: items.length,
        });
      }
    }
  }
  
  return items;
}

// åˆæˆè¯­éŸ³å¹¶ä¿å­˜æ–‡ä»¶
async function synthesizeAndSave(text, index, total) {
  console.log(`[${index}/${total}] åˆæˆ: "${text.substring(0, 50)}${text.length > 50 ? '...' : ''}"`);
  
  try {
    const audioBuffer = await synthesizeSpeech(text, CONFIG.voice);
    const duration = getAudioDuration(audioBuffer);
    
    const filename = `tts_${String(index).padStart(4, '0')}.wav`;
    const filepath = path.join(CONFIG.outputDir, filename);
    
    await fs.writeFile(filepath, audioBuffer);
    
    console.log(`âœ… ä¿å­˜: ${filename} (${duration.toFixed(2)}s)`);
    
    return { filename, duration, text };
  } catch (error) {
    console.error(`âŒ åˆæˆå¤±è´¥: ${error.message}`);
    throw error;
  }
}

// æ›´æ–° JSON ä¸­çš„ duration å’Œæ·»åŠ éŸ³é¢‘æ–‡ä»¶å¼•ç”¨
async function updateScriptConfig(scriptConfig, audioMap) {
  let updateCount = 0;
  
  for (const section of scriptConfig.sections) {
    if (!section.content) continue;
    
    for (const item of section.content) {
      const text = item.read_srt?.trim();
      if (text && audioMap.has(text)) {
        const audioInfo = audioMap.get(text);
        item.duration = audioInfo.duration;
        item.audioFile = audioInfo.filename;
        updateCount++;
      }
    }
  }
  
  console.log(`\nâœ… æ›´æ–°äº† ${updateCount} é¡¹çš„ duration å’ŒéŸ³é¢‘æ–‡ä»¶å¼•ç”¨`);
  return scriptConfig;
}

async function generate() {
  // åŠ è½½ .env æ–‡ä»¶
  await loadEnv();
  
  console.log('ğŸ¤ TTS æ‰¹é‡ç”Ÿæˆè„šæœ¬');
  console.log(`ğŸ“ è„šæœ¬: ${scriptName}`);
  console.log(`ğŸµ å£°éŸ³: ${CONFIG.voice}`);
  
  // æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ˆæ”¯æŒ VITE_ å‰ç¼€å’Œä¸å¸¦å‰ç¼€ä¸¤ç§ï¼‰
  const speechKey = process.env.VITE_AZURE_SPEECH_KEY || process.env.SPEECH_KEY;
  const speechRegion = process.env.VITE_AZURE_SPEECH_REGION || process.env.SPEECH_REGION;
  
  if (!speechKey || !speechRegion) {
    console.error('âŒ é”™è¯¯: ç¼ºå°‘ç¯å¢ƒå˜é‡');
    console.error('   è¯·åœ¨ .env ä¸­é…ç½®:');
    console.error('   VITE_AZURE_SPEECH_KEY=xxx');
    console.error('   VITE_AZURE_SPEECH_REGION=xxx');
    process.exit(1);
  }
  
  // è®¾ç½®åˆ° process.env ä¾›åç»­ä½¿ç”¨
  process.env.SPEECH_KEY = speechKey;
  process.env.SPEECH_REGION = speechRegion;
  
  // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
  await fs.mkdir(CONFIG.outputDir, { recursive: true });
  
  // æ¸…ç†æ—§çš„ TTS æ–‡ä»¶
  console.log('ğŸ§¹ æ¸…ç†æ—§æ–‡ä»¶...');
  try {
    const files = await fs.readdir(CONFIG.outputDir);
    for (const file of files) {
      if (file.endsWith('.wav')) {
        await fs.unlink(path.join(CONFIG.outputDir, file));
      }
    }
    console.log(`âœ… å·²åˆ é™¤ ${files.filter(f => f.endsWith('.wav')).length} ä¸ªæ—§ WAV æ–‡ä»¶\n`);
  } catch (err) {
    console.warn('âš ï¸  æ¸…ç†æ–‡ä»¶æ—¶å‡ºé”™:', err.message);
  }
  
  // åŠ è½½è„šæœ¬é…ç½®
  const scriptConfig = await loadScriptConfig(scriptName);
  
  // æå–æ‰€æœ‰éœ€è¦åˆæˆçš„æ–‡æœ¬
  const readSrtItems = extractReadSrtItems(scriptConfig.sections);
  console.log(`\nğŸ“„ æ‰¾åˆ° ${readSrtItems.length} æ¡éœ€è¦åˆæˆçš„æ–‡æœ¬\n`);
  
  if (readSrtItems.length === 0) {
    console.log('âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦åˆæˆçš„æ–‡æœ¬');
    process.exit(1);
  }
  
  // åˆæˆæ‰€æœ‰æ–‡æœ¬
  const audioMap = new Map();
  for (let i = 0; i < readSrtItems.length; i++) {
    const item = readSrtItems[i];
    const audioInfo = await synthesizeAndSave(item.text, i + 1, readSrtItems.length);
    audioMap.set(item.text, audioInfo);
  }
  
  console.log(`\nğŸ”„ æ›´æ–°è„šæœ¬é…ç½®æ–‡ä»¶...`);
  
  // æ›´æ–°è„šæœ¬é…ç½®
  const updatedConfig = await updateScriptConfig(scriptConfig, audioMap);
  
  // ä¿å­˜æ›´æ–°åçš„é…ç½®
  const scriptPath = path.join(__dirname, `../public/scripts/${scriptName}.json`);
  await fs.writeFile(scriptPath, JSON.stringify(updatedConfig, null, 2));
  
  console.log(`âœ… è„šæœ¬é…ç½®å·²ä¿å­˜: ${scriptPath}`);
  console.log(`\nğŸ‰ å®Œæˆï¼ç”Ÿæˆäº† ${readSrtItems.length} ä¸ªéŸ³é¢‘æ–‡ä»¶`);
}

// é”™è¯¯å¤„ç†
process.on('unhandledRejection', (error) => {
  console.error('âŒ æœªå¤„ç†çš„é”™è¯¯:', error);
  process.exit(1);
});

// è¿è¡Œ
generate().catch((error) => {
  console.error('âŒ è„šæœ¬å¤±è´¥:', error);
  process.exit(1);
});
